#!/usr/bin/env python3
"""
Combines recipe datasets from v2/ and data/ directories into a single file.

This script merges RECIPE_RECORDS from:
- v2/recipes_for_vector_db.py
- data/recipes_for_vector_db.py

Deduplicates by _id (v2 takes precedence as it uses newer BAML processing).
Outputs to data/combined_recipes.py.

Usage:
    python scripts/combine_recipe_datasets.py [--dry-run]
"""

import argparse
import sys
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from v2.recipes_for_vector_db import RECIPE_RECORDS as V2_RECORDS
from data.recipes_for_vector_db import RECIPE_RECORDS as DATA_RECORDS


def combine_datasets(v2_records: list[dict], data_records: list[dict]) -> list[dict]:
    """
    Combine two recipe datasets, deduplicating by _id.

    V2 records take precedence over data records when there are duplicates,
    as v2 uses the newer BAML-based processing.

    Args:
        v2_records: Records from v2/recipes_for_vector_db.py
        data_records: Records from data/recipes_for_vector_db.py

    Returns:
        Combined list of unique records
    """
    # Use dict to deduplicate by _id, v2 records override data records
    combined = {}

    # Add data records first
    for record in data_records:
        combined[record["_id"]] = record

    # Add v2 records (overwriting any duplicates)
    for record in v2_records:
        combined[record["_id"]] = record

    # Sort by _id for consistent output
    return sorted(combined.values(), key=lambda r: r["_id"])


def format_record_for_output(record: dict) -> str:
    """Format a single record as Python code."""
    lines = ["    {"]

    # _id
    lines.append(f'        "_id": {repr(record["_id"])},')

    # content
    lines.append(f'        "content": {repr(record["content"])},')

    # metadata
    lines.append('        "metadata": {')
    metadata = record["metadata"]
    for key, value in metadata.items():
        lines.append(f'            {repr(key)}: {repr(value)},')
    lines.append("        },")

    lines.append("    },")
    return "\n".join(lines)


def generate_output_file(records: list[dict]) -> str:
    """Generate the complete Python file content."""
    header = '''"""
Recipe records prepared for Pinecone vector database ingestion.

Combined from:
- v2/recipes_for_vector_db.py (BAML-processed)
- data/recipes_for_vector_db.py (LLM-classified)

Generated by: scripts/combine_recipe_datasets.py
Schema: data/schemas/basicSchema.json

Usage:
    from data.combined_recipes import RECIPE_RECORDS
"""

RECIPE_RECORDS = [
'''

    record_strings = [format_record_for_output(r) for r in records]

    footer = "]\n"

    return header + "\n".join(record_strings) + "\n" + footer


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Combine recipe datasets from v2/ and data/ directories."
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be done without writing files.",
    )
    args = parser.parse_args()

    print(f"V2 records: {len(V2_RECORDS)}")
    print(f"Data records: {len(DATA_RECORDS)}")

    combined = combine_datasets(V2_RECORDS, DATA_RECORDS)

    # Find duplicates
    v2_ids = {r["_id"] for r in V2_RECORDS}
    data_ids = {r["_id"] for r in DATA_RECORDS}
    duplicates = v2_ids & data_ids

    print(f"Duplicates (v2 takes precedence): {len(duplicates)}")
    if duplicates:
        print(f"  IDs: {sorted(duplicates)}")

    print(f"Combined records: {len(combined)}")

    output_path = project_root / "data" / "combined_recipes.py"

    if args.dry_run:
        print(f"\n[DRY RUN] Would write {len(combined)} records to {output_path}")
        return

    output_content = generate_output_file(combined)
    output_path.write_text(output_content)
    print(f"\nWrote {len(combined)} records to {output_path}")


if __name__ == "__main__":
    main()
